{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "\n",
    "import cv2, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch_snippets import *\n",
    "from torch_snippets import Report\n",
    "from torchvision.ops import nms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cpu\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cpu\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">..<span style=\"color: #800080; text-decoration-color: #800080\">/test/</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "..\u001b[35m/test/\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "\n",
    "\n",
    "# TEST_DATA_DIR = filedialog.askdirectory(\n",
    "#     title=\"Select folder containing images for testing\"\n",
    "# )\n",
    "TEST_DATA_DIR = \"../test/\"\n",
    "print(TEST_DATA_DIR)\n",
    "TEST_JSON_PATH = \"../test/metadata.jsonl\"\n",
    "TEST_PREPROCESSED_CSV_PATH = \"../test/annotations_test.csv\"\n",
    "MODEL_PATH = \"../model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  file_name                                            objects\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.</span>png  <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bbox'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.</span>png  <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bbox'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.</span>png  <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bbox'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100.</span>png  <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bbox'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101.</span>png  <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'bbox'</span>: <span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "  file_name                                            objects\n",
       "\u001b[1;36m0\u001b[0m     \u001b[1;36m0.\u001b[0mpng  \u001b[1m{\u001b[0m\u001b[32m'bbox'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m100\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m130\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m80\u001b[0m, \u001b[1;36m80\u001b[0m, \u001b[1;36m90\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m     \u001b[1;36m1.\u001b[0mpng  \u001b[1m{\u001b[0m\u001b[32m'bbox'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m100\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m130\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m80\u001b[0m, \u001b[1;36m80\u001b[0m, \u001b[1;36m90\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m    \u001b[1;36m10.\u001b[0mpng  \u001b[1m{\u001b[0m\u001b[32m'bbox'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m100\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m130\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m80\u001b[0m, \u001b[1;36m80\u001b[0m, \u001b[1;36m90\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m   \u001b[1;36m100.\u001b[0mpng  \u001b[1m{\u001b[0m\u001b[32m'bbox'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m100\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m130\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m80\u001b[0m, \u001b[1;36m80\u001b[0m, \u001b[1;36m90\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m   \u001b[1;36m101.\u001b[0mpng  \u001b[1m{\u001b[0m\u001b[32m'bbox'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m100\u001b[0m, \u001b[1;36m110\u001b[0m, \u001b[1;36m130\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m80\u001b[0m, \u001b[1;36m80\u001b[0m, \u001b[1;36m90\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_TEST_IMAGE_DETECTIONS = pd.read_json(TEST_JSON_PATH, lines=True)\n",
    "print(DF_TEST_IMAGE_DETECTIONS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessed_data(df=DF_TEST_IMAGE_DETECTIONS, csv_path=TEST_PREPROCESSED_CSV_PATH):\n",
    "    \n",
    "    with open(csv_path, 'w', newline='') as csvfile:\n",
    "        writer_object = csv.writer(csvfile)\n",
    "        writer_object.writerow(['ImageID','XMin','YMin','XMax','YMax','LabelName'])\n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        writer_object = csv.writer(csvfile)\n",
    "        for i in range(len(df)):\n",
    "            bboxes = df[\"objects\"][i][\"bbox\"]\n",
    "            categories = df[\"objects\"][i][\"categories\"]\n",
    "            assert(len(bboxes) == len(categories))\n",
    "            for (bbox, category) in zip(bboxes, categories):\n",
    "                new_row = []\n",
    "                image_id = str(df[\"file_name\"][i]).split(\".\")[0]\n",
    "                new_row.append(image_id)\n",
    "                x_min = bbox[0]\n",
    "                y_min = bbox[1]\n",
    "                x_max = bbox[2]\n",
    "                y_max = bbox[3]\n",
    "                new_row.extend([x_min, y_min, x_max, y_max, str(category)])\n",
    "                writer_object.writerow(new_row)\n",
    "                # print(new_row)\n",
    "\n",
    "\n",
    "create_preprocessed_data(DF_TEST_IMAGE_DETECTIONS, TEST_PREPROCESSED_CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   ImageID  XMin  YMin  XMax  YMax  LabelName\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">90</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">130</span>          <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   ImageID  XMin  YMin  XMax  YMax  LabelName\n",
       "\u001b[1;36m0\u001b[0m        \u001b[1;36m0\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m110\u001b[0m   \u001b[1;36m130\u001b[0m          \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m        \u001b[1;36m0\u001b[0m    \u001b[1;36m80\u001b[0m    \u001b[1;36m80\u001b[0m    \u001b[1;36m90\u001b[0m   \u001b[1;36m100\u001b[0m          \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m        \u001b[1;36m1\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m110\u001b[0m   \u001b[1;36m130\u001b[0m          \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m3\u001b[0m        \u001b[1;36m1\u001b[0m    \u001b[1;36m80\u001b[0m    \u001b[1;36m80\u001b[0m    \u001b[1;36m90\u001b[0m   \u001b[1;36m100\u001b[0m          \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m4\u001b[0m       \u001b[1;36m10\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m100\u001b[0m   \u001b[1;36m110\u001b[0m   \u001b[1;36m130\u001b[0m          \u001b[1;36m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DF_PREPROCESSED_TEST_IMAGE_DETECTIONS = pd.read_csv(TEST_PREPROCESSED_CSV_PATH)\n",
    "print(DF_PREPROCESSED_TEST_IMAGE_DETECTIONS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label2target = {l:t+1 for t,l in enumerate(DF_PREPROCESSED_TEST_IMAGE_DETECTIONS['LabelName'].unique())}\n",
    "label2target['background'] = 0\n",
    "target2label = {t:l for l,t in label2target.items()}\n",
    "background_class = label2target['background']\n",
    "num_classes = len(label2target)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img):\n",
    "    img = torch.tensor(img).permute(2,0,1)\n",
    "    return img.to(device).float().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenDataset(torch.utils.data.Dataset):\n",
    "    w, h = 224, 224\n",
    "    def __init__(self, df, image_dir=TEST_DATA_DIR):\n",
    "        self.image_dir = image_dir\n",
    "        self.files = glob(self.image_dir+'/*.png')\n",
    "        self.df = df\n",
    "        self.image_infos = df.ImageID.unique()\n",
    "    def __getitem__(self, ix):\n",
    "        # load images and masks\n",
    "        image_id = self.image_infos[ix]\n",
    "        # img_path = find(str(image_id), self.files)\n",
    "        img_path = os.path.join(self.image_dir, str(image_id) + \".png\")\n",
    "        print(img_path)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_w, img_h = img.size\n",
    "        img = np.array(img.resize((self.w, self.h), resample=Image.BILINEAR))/255.\n",
    "        data = self.df[self.df['ImageID'] == image_id]\n",
    "        labels = data['LabelName'].values.tolist()\n",
    "        labels = np.array(labels)\n",
    "        boxes = data[['XMin','YMin','XMax','YMax']].values\n",
    "        # boxes[:,[0,2]] *=  np.float64(self.w)/np.float64(img_w)\n",
    "        # boxes[:,[1,3]] *=  np.float64(self.h)/np.float64(img_h)\n",
    "        boxes[:,[0,2]] = ((boxes[:,[0,2]] * np.float64(self.w)) / np.float64(img_w))\n",
    "        boxes[:,[1,3]] = ((boxes[:,[1,3]] * np.float64(self.h)) / np.float64(img_h))\n",
    "        # boxes[:,[0,2]] /=  np.float64(img_w)\n",
    "        # boxes[:,[1,3]] /=  np.float64(img_h)\n",
    "        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0]) \n",
    "        boxes = boxes[keep]\n",
    "        labels = labels[keep]\n",
    "        boxes = boxes.astype(np.uint32).tolist() # convert to absolute coordinates\n",
    "        if len(boxes) == 0:\n",
    "          target = {}\n",
    "          target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
    "          target[\"labels\"] = torch.zeros((0, 1), dtype=torch.int64)\n",
    "        else:\n",
    "          # torch FRCNN expects ground truths as a dictionary of tensors\n",
    "          target = {}\n",
    "          target[\"boxes\"] = torch.Tensor(boxes).float()\n",
    "          target[\"labels\"] = torch.Tensor([label2target[i] for i in labels]).long()\n",
    "        img = preprocess_image(img)\n",
    "        return img, target\n",
    "    def collate_fn(self, batch):\n",
    "        return tuple(zip(*batch)) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = DF_PREPROCESSED_TEST_IMAGE_DETECTIONS\n",
    "\n",
    "final_test_ds = OpenDataset(final_test_df)\n",
    "\n",
    "final_test_loader = DataLoader(final_test_ds, batch_size=4, collate_fn=final_test_ds.collate_fn, drop_last=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/private_shared/ship-detection/JupyterNotebooks/inference.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.233.36.53/private_shared/ship-detection/JupyterNotebooks/inference.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m get_model()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.233.36.53/private_shared/ship-detection/JupyterNotebooks/inference.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(MODEL_PATH \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mmodel_faster_rcnn_epoch15_ship_detector.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1049\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1047\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1048\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1049\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1051\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1053\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1019\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1018\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1019\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   1021\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39m_UntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:175\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    174\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 175\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    176\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py:157\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_UntypedStorage(obj\u001b[39m.\u001b[39mnbytes(), device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(location))\n\u001b[1;32m    156\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39;49mcuda(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_utils.py:78\u001b[0m, in \u001b[0;36m_cuda\u001b[0;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m new_type(indices, values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_UntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize(), device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m))\u001b[39m.\u001b[39;49mcopy_(\u001b[39mself\u001b[39;49m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.load_state_dict(torch.load(MODEL_PATH + \"model_faster_rcnn_epoch15_ship_detector.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_output(output):\n",
    "    'convert tensors to numpy arrays'\n",
    "    bbs = output['boxes'].cpu().detach().numpy().astype(np.uint16)\n",
    "    # print(bbs)\n",
    "    labels = np.array([target2label[i] for i in output['labels'].cpu().detach().numpy()])\n",
    "    confs = output['scores'].cpu().detach().numpy()\n",
    "    ixs = nms(torch.tensor(bbs.astype(np.float32)), torch.tensor(confs), 0.05)\n",
    "    bbs, confs, labels = [tensor[ixs] for tensor in [bbs, confs, labels]]\n",
    "\n",
    "    if len(ixs) == 1:\n",
    "        bbs, confs, labels = [np.array([tensor]) for tensor in [bbs, confs, labels]]\n",
    "    return bbs.tolist(), confs.tolist(), labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for ix, (images, targets) in enumerate(final_test_loader):\n",
    "    if ix==3: break\n",
    "    images = [im for im in images]\n",
    "    outputs = model(images)\n",
    "    print(outputs)\n",
    "\n",
    "    for ix, output in enumerate(outputs):\n",
    "        bbs, confs, labels = decode_output(output)\n",
    "        info = [f'{l}@{c:.2f}' for l,c in zip(labels, confs)]\n",
    "        show(images[ix].cpu().permute(1,2,0), bbs=bbs, texts=labels, sz=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AptivCV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
